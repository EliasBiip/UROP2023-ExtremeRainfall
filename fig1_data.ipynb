{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import netCDF4 as nc\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import multiprocessing\n",
    "from percentile_fun import compute_percentile\n",
    "import matplotlib.cm as cm\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from rain_get import rain_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_time_series(arr, loc_num):\n",
    "    \"\"\"generate data across time, by interpreting the 3rd dim as time\"\"\"\n",
    "    # [time,lon,lat]:[1748,1440,400] -> [57600,1748]:[data_plot,time]\n",
    "    out = []\n",
    "    for n in range(0,loc_num):\n",
    "        for l in arr[:, :, n].T:\n",
    "            out.append(l)\n",
    "    out = np.array(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def data_clean(arr, chunk_size):\\n    num_processes = multiprocessing.cpu_count()\\n    pool = multiprocessing.Pool(processes=num_processes)\\n    results = []\\n    for i in range(0, arr.shape[0], chunk_size):\\n        chunk = arr[i:i+chunk_size]\\n        result = pool.apply_async(rain_fill, (chunk,))\\n        results.append(result)\\n    pool.close()\\n    pool.join()\\n    return results\\n\\nif __name__ == '__main__':\\n    percen_rain = data_clean(time_series[:288000], 72000)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def data_clean(arr, chunk_size):\n",
    "    num_processes = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(processes=num_processes)\n",
    "    results = []\n",
    "    for i in range(0, arr.shape[0], chunk_size):\n",
    "        chunk = arr[i:i+chunk_size]\n",
    "        result = pool.apply_async(rain_fill, (chunk,))\n",
    "        results.append(result)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    percen_rain = data_clean(time_series[:288000], 72000)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lon and lat from abitary dates\n",
    "test_set = nc.Dataset('data/20011224.nc4')\n",
    "lat = test_set['lat'][:]\n",
    "lon = test_set['lon'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "(1440, 400)\n",
      "184\n",
      "(1440, 400)\n",
      "276\n",
      "(1440, 400)\n",
      "368\n",
      "(1440, 400)\n",
      "460\n",
      "(1440, 400)\n",
      "552\n",
      "(1440, 400)\n",
      "644\n",
      "(1440, 400)\n",
      "736\n",
      "(1440, 400)\n",
      "828\n",
      "(1440, 400)\n",
      "920\n",
      "(1440, 400)\n",
      "1012\n",
      "(1440, 400)\n",
      "1104\n",
      "(1440, 400)\n",
      "1196\n",
      "(1440, 400)\n",
      "1288\n",
      "(1440, 400)\n",
      "1380\n",
      "(1440, 400)\n",
      "1472\n",
      "(1440, 400)\n",
      "1564\n",
      "(1440, 400)\n",
      "1656\n",
      "(1440, 400)\n",
      "1748\n",
      "(1440, 400)\n"
     ]
    }
   ],
   "source": [
    "# read precipitation data from all the dates between 1998-2016\n",
    "# JJA = 92\n",
    "pcp_whole = []\n",
    "dates_whole = []\n",
    "years = [n for n in range(1998,2017)]\n",
    "for y in years:\n",
    "    start = datetime.date(y,6,1)\n",
    "    for n in range(1,93):\n",
    "        #change this according to the position\n",
    "        str = 'data/' +  start.strftime(\"%Y%m%d\") + '.nc4'\n",
    "        nc_da = nc.Dataset(str)\n",
    "        pcp_whole.append(nc_da['precipitation'][:])\n",
    "        dates_whole.append(start.strftime(\"%Y%m%d\"))\n",
    "        start = start + datetime.timedelta(days=1)\n",
    "    print(len(pcp_whole))\n",
    "    print(pcp_whole[0].shape)\n",
    "pcp_whole = np.array(pcp_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rainning days are defined as the days with >= 1 precipitation \n",
    "day_rain = np.where(pcp_whole>=1,pcp_whole, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576000, 1748)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will take some time\n",
    "# what it does is explained in the function\n",
    "time_series = gen_time_series(day_rain,400)\n",
    "time_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliashanlm/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1395: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/Users/eliashanlm/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1395: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/Users/eliashanlm/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1395: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "/Users/eliashanlm/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1395: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n"
     ]
    }
   ],
   "source": [
    "# use multi processing to compute the percentiles\n",
    "def parallel_percentile(arr, chunk_size):\n",
    "    num_processes = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(processes=num_processes)\n",
    "\n",
    "    results = []\n",
    "    for i in range(0, arr.shape[0], chunk_size):\n",
    "        chunk = arr[i:i+chunk_size]\n",
    "        result = pool.apply_async(compute_percentile, (chunk,))\n",
    "        results.append(result)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    percentiles = np.concatenate([result.get() for result in results])\n",
    "\n",
    "    return percentiles\n",
    "if __name__ == '__main__':\n",
    "    percen = parallel_percentile(time_series, 72000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the precentiles\n",
    "np.savetxt('percentile_rain.txt', percen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
